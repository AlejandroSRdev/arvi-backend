# üìä AN√ÅLISIS EXHAUSTIVO: ai_service.dart

**Fecha:** 2025-12-26
**Archivo analizado:** `frontend-reference/services/ai_service.dart`
**L√≠neas totales:** ~1000+
**Prop√≥sito:** Identificar funciones cr√≠ticas para migrar al backend

---

## üîç FUNCIONES DETECTADAS

### FUNCIONES CR√çTICAS - üî¥ MIGRAR AL BACKEND

#### 1. **`_callAIChat()`** (l√≠neas 153-368)
**¬øQu√© hace?**
- Funci√≥n universal de llamada a OpenAI (GPT) y Google Gemini
- Determina el modelo a usar (default: `gemini-2.5-flash`)
- Ejecuta llamadas HTTP directas a las APIs
- **Descuenta energ√≠a autom√°ticamente** (solo para Gemini, l√≠neas 336-348)

**Llamadas API:**
- OpenAI: `https://api.openai.com/v1/chat/completions`
- Gemini: `https://generativelanguage.googleapis.com/v1beta/models/{modelo}:generateContent`

**Claves API expuestas:**
- `Secrets.openAIapiKey` (l√≠nea 207)
- `Secrets.geminiAIApiKey` (l√≠nea 261)

**L√≥gica cr√≠tica:**
- Si modelo empieza con 'gpt' ‚Üí OpenAI
- Si no ‚Üí Gemini
- Par√°metros: `temperature`, `maxTokens`, `forceJson`
- **CONSUME ENERG√çA** calculando tokens (l√≠neas 337-342):
  ```dart
  final tokens = (tokensRespuesta + (tokensPrompt * 0.30)).round();
  final energiaARestar = (tokens / 100).ceil();
  await EnergyService().decrementEnergyBy(energiaARestar);
  ```

**Decisi√≥n:** ‚úÖ **MIGRAR COMPLETA AL BACKEND**
- Protege claves API
- Valida energ√≠a ANTES de llamar
- Registra uso en Firestore

---

#### 2. **`convertirAStrictJSON()`** (l√≠neas 54-148)
**¬øQu√© hace?**
- Conversi√≥n de texto libre a JSON estructurado
- **Modelo fijo:** `gpt-4o-mini` (par√°metro default, l√≠nea 59)
- Usa `forceJson: true` para response_format
- Llama a `_callAIChat()` internamente

**Par√°metros:**
```dart
required String contenidoLibre
required Map<String, dynamic> estructuraObjetivo
required String idioma
required String nombreFuncion
String modelo = "gpt-4o-mini"
```

**L√≥gica cr√≠tica:**
- Construye prompt con schema objetivo
- Usa temperature 0.0 (determinista)
- maxTokens: 1500
- Parsea respuesta JSON
- Fallback seguro si falla

**Decisi√≥n:** ‚úÖ **MIGRAR AL BACKEND**
- Modelo fijo (siempre gpt-4o-mini)
- Consume energ√≠a (v√≠a `_callAIChat`)
- L√≥gica de negocio cr√≠tica

---

#### 3. **`generarFraseHome()`** (l√≠neas 524-575)
**¬øQu√© hace?**
- Genera frase breve para pantalla principal (‚â§25 palabras)
- **Modelo:** `gemini-2.0-flash` (l√≠nea 567)
- Usa memoria del asistente y contexto del usuario

**Decisi√≥n:** üü° **MIGRAR PARCIALMENTE**
- **Backend:** Llamada a Gemini con validaci√≥n de energ√≠a
- **Flutter:** Construcci√≥n del prompt (tiene BuildContext)

---

#### 4. **`generarComentarioPaso()`** (l√≠neas 578-658)
**¬øQu√© hace?**
- Genera comentario filos√≥fico sobre respuesta del usuario en reprogramaci√≥n
- **Modelo:** `gemini-2.5-flash` (l√≠nea 657)
- M√°x 6 l√≠neas, tono filos√≥fico (Stoico, Jungiano, etc.)

**Decisi√≥n:** üü° **MIGRAR PARCIALMENTE**
- **Backend:** Llamada a Gemini
- **Flutter:** Prompt con localizaci√≥n

---

#### 5. **`generarResultadoReprogramacion()`** (l√≠neas 661-754)
**¬øQu√© hace?**
- Genera informe final de reprogramaci√≥n (3-5 p√°rrafos)
- **Modelo:** `gemini-2.5-pro` (l√≠nea 753)
- Analiza 5 pasos del proceso

**Decisi√≥n:** üü° **MIGRAR PARCIALMENTE**
- **Backend:** Llamada a Gemini Pro
- **Flutter:** Construcci√≥n del prompt

---

#### 6. **`generarResumenEjecucion()`** (l√≠neas 756-1000+)
**¬øQu√© hace?**
- Genera resumen operativo del d√≠a
- **Modelo:** NO ESPECIFICADO en el fragmento le√≠do (probablemente Gemini)
- Retorna `ResumenEjecucion` (JSON estructurado)
- An√°lisis de actividades, desviaciones, notas

**Decisi√≥n:** üü° **MIGRAR PARCIALMENTE**
- **Backend:** Llamada a IA + validaci√≥n JSON
- **Flutter:** Construcci√≥n del prompt con plan diario

---

### FUNCIONES DE SOPORTE - üîµ MANTENER EN FLUTTER

#### 7. **`limpiarTextoIA()`** (l√≠neas 22-35)
**¬øQu√© hace?**
- Limpia caracteres Unicode raros de respuestas
- Reemplaza comillas tipogr√°ficas, etc.

**Decisi√≥n:** üîµ **MANTENER EN FLUTTER** (utilidad de UI)

---

#### 8. **`calcularTokensGeminiSolo()`** (l√≠neas 38-41)
**¬øQu√© hace?**
- Estima tokens: `longitud / 3.7`

**Decisi√≥n:** üü° **MIGRAR AL BACKEND**
- Necesario para calcular consumo de energ√≠a

---

#### 9. **`generarMemoriaCompleta()`** (l√≠neas 395-433)
**¬øQu√© hace?**
- Construye string de memoria del asistente
- Usa `AppLocalizations` (localizaci√≥n)

**Decisi√≥n:** üîµ **MANTENER EN FLUTTER**
- Depende de BuildContext y localizaci√≥n
- Solo construye strings, no llama APIs

---

#### 10. **`crearContextoConMemoria()`** (l√≠neas 437-460)
**¬øQu√© hace?**
- Crea array de mensajes con memoria como system message

**Decisi√≥n:** üîµ **MANTENER EN FLUTTER**
- Solo prepara datos, no llama APIs

---

## üéØ CLASIFICACI√ìN FINAL

### üî¥ CR√çTICO - MIGRAR AL BACKEND (OBLIGATORIO)

| Funci√≥n | Motivo | Prioridad |
|---------|--------|-----------|
| `_callAIChat` | Claves API expuestas, consume energ√≠a | üî¥ Alta |
| `convertirAStrictJSON` | Claves API, modelo fijo gpt-4o-mini | üî¥ Alta |

### üü° ALTO - MIGRAR PARCIALMENTE

| Funci√≥n | Backend | Flutter |
|---------|---------|---------|
| `generarFraseHome` | Llamada Gemini + energ√≠a | Prompt con localizaci√≥n |
| `generarComentarioPaso` | Llamada Gemini + energ√≠a | Prompt con contexto |
| `generarResultadoReprogramacion` | Llamada Gemini Pro + energ√≠a | Prompt con pasos |
| `generarResumenEjecucion` | Llamada IA + validaci√≥n JSON | Prompt con plan diario |

### üîµ MEDIO - MANTENER EN FLUTTER

| Funci√≥n | Motivo |
|---------|--------|
| `limpiarTextoIA` | Utilidad de UI |
| `generarMemoriaCompleta` | Depende de localizaci√≥n |
| `crearContextoConMemoria` | Solo prepara datos |

### ‚ö™ BAJO - HELPERS

| Funci√≥n | Decisi√≥n |
|---------|----------|
| `calcularTokensGeminiSolo` | Migrar al backend (para energ√≠a) |

---

## üîë DESCUBRIMIENTOS CR√çTICOS

### 1. **Selecci√≥n de Modelo NO es por plan del usuario**

‚ùå **CORRECCI√ìN NECESARIA:**
En el an√°lisis inicial asum√≠ que el modelo se selecciona seg√∫n el plan del usuario, pero en realidad:

- `_callAIChat` recibe el modelo como **par√°metro opcional**
- Default: `gemini-2.5-flash` (l√≠nea 162)
- Cada funci√≥n que llama a `_callAIChat` **especifica su propio modelo**:
  - `convertirAStrictJSON`: `gpt-4o-mini` (l√≠nea 59)
  - `generarFraseHome`: `gemini-2.0-flash` (l√≠nea 567)
  - `generarComentarioPaso`: `gemini-2.5-flash` (l√≠nea 657)
  - `generarResultadoReprogramacion`: `gemini-2.5-pro` (l√≠nea 753)

**Conclusi√≥n:** El modelo se selecciona por **tipo de funci√≥n**, NO por plan del usuario.

---

### 2. **Consumo de Energ√≠a SOLO en Gemini**

üö® **ASIM√âTRICO:**
- Gemini descuenta energ√≠a **autom√°ticamente** en `_callAIChat` (l√≠neas 336-348)
- OpenAI **NO descuenta energ√≠a** en `_callAIChat`

**Pregunta cr√≠tica:** ¬øEsto es intencional o es un bug?

**Decisi√≥n para backend:**
‚úÖ Consumir energ√≠a **SIEMPRE** (tanto OpenAI como Gemini)

---

### 3. **C√°lculo de Energ√≠a (Gemini)**

```dart
final tokensPrompt = calcularTokensGeminiSolo(prompt);
final tokensRespuesta = calcularTokensGeminiSolo(respuesta);
final tokens = (tokensRespuesta + (tokensPrompt * 0.30)).round();
final energiaARestar = (tokens / 100).ceil();
```

**F√≥rmula:**
1. Tokens de respuesta (completos)
2. Tokens de prompt (solo 30%)
3. Total tokens = respuesta + (prompt √ó 0.30)
4. Energ√≠a = ceil(tokens / 100)

**Ejemplo:**
- Prompt: 1000 chars ‚Üí ~270 tokens
- Respuesta: 500 chars ‚Üí ~135 tokens
- Total: 135 + (270 √ó 0.30) = 216 tokens
- Energ√≠a: ceil(216 / 100) = 3

---

### 4. **Redirecci√≥n a Suscripci√≥n cuando energ√≠a = 0**

```dart
if (energiaRestante != null && energiaRestante <= 0) {
  WidgetsBinding.instance.addPostFrameCallback((_) {
    NavigationService.instance.pushAndRemoveUntil(
      const SubscriptionScreen(),
    );
  });
}
```

**Decisi√≥n para backend:**
‚ùå NO migrar (es l√≥gica de UI)
‚úÖ Backend solo debe lanzar error `INSUFFICIENT_ENERGY`

---

## üìù RECOMENDACIONES PARA LA MIGRACI√ìN

### Arquitectura del Backend

```javascript
// src/services/aiService.js

/**
 * FUNCI√ìN PRINCIPAL: callAI
 *
 * Centraliza TODAS las llamadas a OpenAI/Gemini
 *
 * @param {string} userId - ID del usuario
 * @param {array} messages - Mensajes del chat
 * @param {object} options - Opciones
 *   - model: Modelo espec√≠fico (gpt-4o-mini, gemini-2.5-flash, etc.)
 *   - temperature: 0.0 - 1.0
 *   - maxTokens: L√≠mite de tokens
 *   - forceJson: Boolean (response_format)
 */
async function callAI(userId, messages, options = {}) {
  // 1. Validar energ√≠a ANTES de llamar
  // 2. Ejecutar llamada seg√∫n modelo
  // 3. Calcular tokens consumidos
  // 4. Descontar energ√≠a DESPU√âS de respuesta exitosa
  // 5. Registrar uso en Firestore
  // 6. Retornar respuesta
}

/**
 * FUNCI√ìN ESPEC√çFICA: convertToJSON
 *
 * Siempre usa gpt-4o-mini
 */
async function convertToJSON(userId, content, schema) {
  return callAI(userId, [...], {
    model: 'gpt-4o-mini',
    forceJson: true,
    temperature: 0.0,
    maxTokens: 1500
  });
}
```

### Endpoints Necesarios

```
POST /api/ai/call
POST /api/ai/convert-json
POST /api/ai/generate-home-phrase
POST /api/ai/generate-comment
POST /api/ai/generate-reprogramming-result
POST /api/ai/generate-execution-summary
```

---

## ‚úÖ PLAN DE ACCI√ìN

### FASE 1: Core Functions (URGENTE)
1. ‚úÖ Migrar `_callAIChat` ‚Üí `callAI`
2. ‚úÖ Migrar `convertirAStrictJSON` ‚Üí `convertToJSON`
3. ‚úÖ Implementar c√°lculo de tokens Gemini
4. ‚úÖ Implementar consumo de energ√≠a universal

### FASE 2: Specific Functions (ALTA PRIORIDAD)
5. ‚úÖ Endpoint para `generarFraseHome`
6. ‚úÖ Endpoint para `generarComentarioPaso`
7. ‚úÖ Endpoint para `generarResultadoReprogramacion`
8. ‚úÖ Endpoint para `generarResumenEjecucion`

### FASE 3: Documentation
9. ‚úÖ Documentar endpoints en README
10. ‚úÖ Documentar modelos por tipo de funci√≥n

---

**Conclusi√≥n:** La migraci√≥n requiere separar la **l√≥gica de negocio** (llamadas API, energ√≠a) de la **construcci√≥n de prompts** (que debe quedarse en Flutter por depender de localizaci√≥n y contexto del usuario).

